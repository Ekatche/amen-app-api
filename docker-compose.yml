version: "3.9"

services:
  app:
    build:
      context: .
      args:
        - DEV=true
    ports:
      - "8000:8000"
    volumes:
      - ./app:/app
    command: >
      sh -c "python manage.py wait_for_db &&
             python manage.py migrate &&
             python manage.py runserver 0.0.0.0:8000"
    env_file:
      - ./.env.dev.txt
    environment:
      - ES_HOST=elasticsearch
    depends_on:
      - redis
      - db
      - elasticsearch
      - pgadmin
    networks:
      - es_network


  elasticsearch:
    #  elastic search is used for research optimisation
    container_name: search
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.8
    env_file:
      - ./.env.dev.txt
    ports:
      - "9200:9200"
    volumes:
      - ./elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml
      - data02:/usr/share/elasticsearch/data
    environment:
      ES_JAVA_OPTS: '-Xms256m -Xmx256m'
      cluster.routing.allocation.disk.threshold_enabled: "false"
      bootstrap.memory_lock: "true"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    networks:
      - es_network

  db:
    #    the database where is stored the app data
    image: postgres:13-alpine
    container_name: local_db
    volumes:
      - dev-db-data:/var/lib/postgresql/data
    env_file:
      - ./.env.dev.txt
    ports:
      - "5432:5432"
    networks:
      - es_network

  pgadmin:
    #    interface to access the pg database
    container_name: pgadmin4_container
    image: dpage/pgadmin4
    restart: always
    env_file:
      - ./.env.dev.txt
    ports:
      - "5050:80"
    volumes:
      - pgadmin-data:/var/lib/pgadmin
    links:
      - "db:pgsql-server"
    networks:
        - es_network

  redis:
    #    redis is our messages broker, we sent tasks to redis and it disctibutes it to the celery workers
    container_name: redis
    restart: always
    image: redis:alpine
    ports:
      - "6379:6379"

  celery:
    #    celery is used to automate tasks that updated the database
    container_name: celery_ecommerce_amen
    restart: always
    build:
      context: .
    command: celery -A config worker -l info
    volumes:
      - ./app:/app
    env_file:
      - ./.env.dev.txt
    depends_on:
      - redis
      - db
      - app

  celery-beat:
    #    celery beat is used to schedule celery tasks
    container_name: celery_beat_ecommerce_amen
    restart: always
    build:
      context: .
    command: celery -A config beat -l info
    depends_on:
      - redis
      - celery
    volumes:
      - ./app:/app

  flower:
    #    flower is used to manage celery tasks, see if they fail or succeed and see the errors messages
    container_name: flower_ecommerce
    image: mher/flower
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - FLOWER_PORT=8888
    ports:
      - "8888:8888"

volumes:
  dev-db-data:
  pgadmin-data:
  data02:
    driver: local

networks:
  es_network:
    driver: bridge

